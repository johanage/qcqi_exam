{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from matplotlib.pyplot import rc\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "font = {'family' : 'monospace',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : '12'}\n",
    "rc('font', **font)  # pass in the font dict as kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8aff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import IBMQ\n",
    "mytoken = '105ccb14a9f37cd5ce743b6e47f48c0da24790f0432159de03b522fa68d16848eb741951dcbe5f2aa0af2e0ce3abd5be008d9e37042da2b95e83dbef772850f0'\n",
    "IBMQ.save_account(mytoken, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5cbf89-0831-425b-96b0-fb83f95165ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Importing standard Qiskit libraries\n",
    "from qiskit import QuantumCircuit, transpile, Aer, IBMQ, execute\n",
    "from qiskit.tools.jupyter import *\n",
    "from qiskit.visualization import *\n",
    "from qiskit.providers.aer import QasmSimulator\n",
    "from matplotlib import pyplot as plt\n",
    "import qiskit.providers.aer.noise as noise\n",
    "# Loading your IBM Quantum account(s)\n",
    "provider = IBMQ.load_account()\n",
    "for backend in provider.backends():\n",
    "    print(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64016e8e-996b-47b5-9376-cb5a92d2f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.extensions import UnitaryGate\n",
    "sqrtX = UnitaryGate([[1/np.sqrt(2), -1/np.sqrt(2)*1j], [-1/np.sqrt(2)*1j, 1/np.sqrt(2)]], label='X^1/2')\n",
    "sqrtY = UnitaryGate([[1/np.sqrt(2), -1/np.sqrt(2)], [1/np.sqrt(2), 1/np.sqrt(2)]], label='Y^1/2')\n",
    "sqrtW = UnitaryGate([[1/np.sqrt(2), -1/np.sqrt(2)*np.sqrt(1j)], [1/np.sqrt(2)*np.sqrt(-1j), 1/np.sqrt(2)]], label='W^1/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6b219-feb3-44ce-bb03-60e29ea1ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that add gate works\n",
    "qc = QuantumCircuit(3)\n",
    "qc.draw()\n",
    "qc.append(sqrtX, [0])\n",
    "qc.append(sqrtY, [1])\n",
    "qc.append(sqrtW, [2])\n",
    "qc.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d403c-e316-401e-abee-36c2980024c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_gate(num_qubits, operands):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - operands - gates to choose from\n",
    "    Out:\n",
    "     - Random unitary gate from operands\n",
    "    \"\"\"\n",
    "    choices = random.choices(population = operands, k = num_qubits)\n",
    "    if len(choices) == 1:\n",
    "        return choices[0]\n",
    "    return choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a70161-3716-45d0-b348-f3a1296f59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_operands = [sqrtX, sqrtY, sqrtW]\n",
    "rand_gate_test = random_gate(num_qubits = 1, operands= std_operands)\n",
    "rand_gate_test.to_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e04f3f-3661-4455-8c82-8236f759b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rqc(num_qubits, depth, operands = std_operands, seed = 2022):\n",
    "    reg = [i for i in range(num_qubits)]\n",
    "    random.seed(seed)\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qc.h([i for i in range(qc.num_qubits)])\n",
    "    choices = [None]*num_qubits\n",
    "    for i in range(depth):\n",
    "        # cz gate layer\n",
    "        for j in range(num_qubits):\n",
    "            choice = random_gate(num_qubits=1, operands = operands)\n",
    "            while choice == choices[j]:\n",
    "                choice = random_gate(num_qubits=1, operands = operands)\n",
    "            choices[j] = choice # store to make sure the same gate does not get chosen two times consequtively\n",
    "            qc.unitary(choice, [j], label = choice.label)\n",
    "        # random gate layer\n",
    "        if i%2 == 0:\n",
    "            igate = np.arange(0,num_qubits-1, 2)\n",
    "            for j in igate: \n",
    "                qc.cz(j, j+1)\n",
    "        else:\n",
    "            igate = np.arange(1,num_qubits-1, 2)\n",
    "            for j in igate:\n",
    "                qc.cz(j, j+1)\n",
    "        qc.barrier()\n",
    "                   \n",
    "    return qc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898656e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylatexenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fba39-84c9-4040-8902-f7f3c25a8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc5 = gen_rqc(num_qubits=15, depth = 40)\n",
    "qc5.save_statevector()\n",
    "print(qc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c7ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_2gates(num_qubits, depth):\n",
    "    even = (num_qubits%2 == 0)\n",
    "    if even:\n",
    "        g2 = (num_qubits-1)*depth//2 +1 # every second layer there is 1 cz gate less, the +1 is because // rounds down to closest integer\n",
    "    else:\n",
    "        g2 = (num_qubits//2)*depth # // rounds down to closes integer\n",
    "    return g2\n",
    "num_2gates(14, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0394a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_test = gen_rqc(num_qubits=14, depth = 5)\n",
    "print(circ_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a640d-f8db-467f-aac9-541547e76783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.providers.aer import AerSimulator\n",
    "from qiskit.providers.aer.noise import NoiseModel\n",
    "backend = provider.get_backend('ibmq_lima')\n",
    "backend_noise_model = NoiseModel.from_backend(backend)\n",
    "\n",
    "#Create the simulators\n",
    "\n",
    "# Create ideal simulator backend and transpile circuit\n",
    "sim_ideal = AerSimulator(method='statevector')\n",
    "\n",
    "#Design noise model\n",
    "depth = 40\n",
    "# Error parameters\n",
    "r = 0.0005\n",
    "rinit = r # error rate for initialisation of the qrc\n",
    "r1 = r/10 # gate 1 error rate\n",
    "r2 = r # gate 2 error rate\n",
    "g1 = 15*depth # number of single qbit gates\n",
    "g2 = num_2gates(num_qubits = 15, depth = depth) # number of 2-qbit gates\n",
    "rmes = r # error rate for measurements\n",
    "\n",
    "# initialise the noise model\n",
    "designed_noise_model = noise.NoiseModel()\n",
    "# Construct the error\n",
    "bit_flip = noise.pauli_error([('X', r), ('I', 1 - r)]) # construct bit-flip error\n",
    "\n",
    "# Depolarizing quantum errors\n",
    "error_1 = noise.depolarizing_error(r1, 1)\n",
    "error_2 = noise.depolarizing_error(r2, 2)\n",
    "\n",
    "designed_noise_model.add_all_qubit_quantum_error(bit_flip, \"reset\")\n",
    "designed_noise_model.add_all_qubit_quantum_error(error_1, ['unitary', 'X^1/2', 'Y^1/2', 'W^1/2'])\n",
    "designed_noise_model.add_all_qubit_quantum_error(error_2, ['cz'])\n",
    "designed_noise_model.add_all_qubit_quantum_error(bit_flip, \"measure\")\n",
    "\n",
    "qc5.measure_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd22571-f176-487f-9abc-1ca36727bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_noise = AerSimulator(noise_model=designed_noise_model)\n",
    "\n",
    "# ideal simulation\n",
    "res_noisefree = sim_ideal.run(qc5).result()\n",
    "state = res_noisefree.get_statevector()\n",
    "pU_test = state.probabilities()\n",
    "\n",
    "# noisy simulation\n",
    "qct5 = transpile(qc5, sim_noise)\n",
    "res_noise = sim_noise.run(qct5, shots=int(1e3)).result()\n",
    "pnoise = res_noise.get_statevector().probabilities_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c52ce1-7bcc-4f94-a9af-0784175051f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit.quantum_info\n",
    "def prob_getcounts(result, qc):\n",
    "    Nshots = sum(result.get_counts(qc).values())\n",
    "    print(Nshots)\n",
    "    x = {}\n",
    "    Nshots = sum(list(result.get_counts().values() ))\n",
    "    for bitstring, count in result.get_counts().items():\n",
    "        bit = bitstring.split(\" \")[0]\n",
    "        x[bit] = count/Nshots\n",
    "    return x\n",
    "# check sum of prob equals 1\n",
    "p_noisefree = prob_getcounts(result = res_noisefree, qc = qc5)\n",
    "p_noisy = prob_getcounts(result = res_noise, qc = qc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400319ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_puexp(probdict_noisy, pU):\n",
    "    norm = 0\n",
    "    puexp = []\n",
    "    for key, value in probdict_noisy.items():\n",
    "        ind = int(key.split(\" \")[0], 2) # indices of the bitstrings, have to split between qubits and classical bits\n",
    "        puexp.append(pU[ind])\n",
    "    puexp = np.array(puexp)\n",
    "    return puexp\n",
    "\n",
    "def compute_entropy(probs):\n",
    "    # print(\"\\n entropy function probs: \", probs)\n",
    "    return - np.sum(probs*np.log(probs))\n",
    "\n",
    "\n",
    "# calculate the cross entropy difference estimate\n",
    "def cross_entropy_est(probdict_noisy, pU, euler_const = 0.577):\n",
    "    num_qubits = len(list(probdict_noisy.keys())[0].split(\" \")[0])\n",
    "    print(\"num_qubits\", num_qubits)\n",
    "    #calculate the estimate of the fidelity aka cross entropy difference\n",
    "    H0 = num_qubits*np.log(2) + euler_const\n",
    "    H_pA_pU = 0\n",
    "    sumpu = 0\n",
    "    nshots = sum(list(probdict_noisy.values() ))\n",
    "    #print(\"nshots\", nshots)\n",
    "    print(\"number of unique samples drawn\", len(list(probdict_noisy.keys())), \"\\ntot number of possible samples\", 2**(num_qubits))\n",
    "    for bistring, count in probdict_noisy.items():\n",
    "        ind = int(bistring.split(\" \")[0], 2) # indices of the bitstrings, have to split between qubits and classical bits\n",
    "        #print(ind, count)\n",
    "        #print([bin(i) for i in range(2**(8))][ind], bistring.split(\" \")[0]) # confirm that the right key is found\n",
    "        sumpu += pU[ind]\n",
    "        #print(count)\n",
    "        #print(\"pU[ind]\", pU[ind])\n",
    "        H_pA_pU += (count/nshots)*np.log( pU[ind] )\n",
    "    #print('sumpu', sumpu)\n",
    "    alpha = H0 + H_pA_pU\n",
    "    return alpha, -H_pA_pU/nshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f95aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"testcount = {'00':100, '01':5, '10':15, '11':80}\n",
    "testpU = [.45, 0.05, 0.1, .4]\n",
    "#testpU1 = [.5, 0.05, 0.1, .4]\n",
    "#get_puexp(testcount, testpU)\n",
    "cross_entropy_est(probdict_noisy = testcount, pU = testpU )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce1bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(prob_noisefree)\n",
    "#cross_entropy_est(probdict_noisy = res_noisefree.get_statevector().probabilities_dict(), pU = pU_test) # probdict from statevector from noisefree simulator for comparison\n",
    "#cross_entropy_est(probdict_noisy = res_noise.get_statevector().probabilities_dict(), pU = pU_test) # probdict from statevector from noisy simulator for comparison\n",
    "cross_entropy_est(probdict_noisy = res_noise.get_counts(qc5), pU = pU_test ) # from getcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0df18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_digital(r, depth, num_qubits):\n",
    "    g1 = num_qubits*depth # number of single qbit gates\n",
    "    g2 = num_2gates(num_qubits = num_qubits, depth = depth) # number of 2-qbit gates\n",
    "    return np.exp(-r*(g1/10 + g2 + 2*num_qubits))\n",
    "alpha_dig_test = alpha_digital(r=r, depth=depth, num_qubits = 9)\n",
    "alpha_dig_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09960a63-2f28-4463-bc40-18f2716a6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cross entropy difference estimate\n",
    "def compute_IPRK(probdict_noisfree, pU, k, euler_const = 0.577):\n",
    "    num_qubits = len(list(probdict_noisfree.keys())[0].split(\" \")[0])\n",
    "    iprk = 0\n",
    "    for key, value in probdict_noisfree.items():\n",
    "        ind = int(key.split(\" \")[0], 2) # indices of the bitstrings, have to split between qubits and classical bits\n",
    "        iprk += np.abs(value* pU[ind] )**(2*k)\n",
    "    return iprk\n",
    "compute_IPRK(probdict_noisfree = p_noisy, pU = pU_test, k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc8235-99a9-4f57-9bd2-e52d6eeeb6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ks = np.arange(2,11,2)\n",
    "df_qs = pd.DataFrame(columns= ['alpha_dig', 'puexp', 'ninstance', 'num_qubits', 'depth', 'pU','entropy','cross_entropy', 'cross_entropy_diff','nshots']+['IPR%i'%k for k in ks])\n",
    "df_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80cd6c9-796a-495f-b5ee-5c51e8afba67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make list of entropy depth pairs\n",
    "def entropy_vs_depth(df = df_qs, r = 0.0005, num_qubits = 15, depth_range = np.arange(20,30,2), Nshots = int(2e3), ninstance = None, ks = None, plot_hist_NpU = False):\n",
    "    N = 2**(num_qubits)\n",
    "    \n",
    "    # get backend and noise model for simulating real hardware\n",
    "    backend = provider.get_backend('ibmq_lima')\n",
    "    hardware_noise_model = NoiseModel.from_backend(backend)\n",
    "    sim_real = QasmSimulator(method='density_matrix', noise_model=hardware_noise_model)\n",
    "    qc = None\n",
    "    for i in range(len(depth_range)):\n",
    "        depth = depth_range[i]\n",
    "        # generate the quantum circuit\n",
    "        if qc is not None:\n",
    "            del qc\n",
    "        qc = gen_rqc(num_qubits=num_qubits, depth = depth)\n",
    "        qc.save_statevector()\n",
    "        \n",
    "        # Create ideal simulator backend and transpile circuit\n",
    "        sim_ideal = AerSimulator(method='statevector')\n",
    "        \n",
    "        #Design noise model\n",
    "\n",
    "        # Error parameters\n",
    "        rinit = r # error rate for initialisation of the qrc\n",
    "        r1 = r/10 # gate 1 error rate\n",
    "        r2 = r # gate 2 error rate\n",
    "        g1 = num_qubits*depth # number of single qbit gates\n",
    "        g2 = num_2gates(num_qubits = num_qubits, depth = depth) # number of 2-qbit gates\n",
    "        rmes = r # error rate for measurements\n",
    "        \n",
    "        # Initialise the noise model\n",
    "        designed_noise_model = noise.NoiseModel()\n",
    "        \n",
    "        # Construct the errors\n",
    "        # bitflip error\n",
    "        bit_flip = noise.pauli_error([('X', r), ('I', 1 - r)]) # construct bit-flip error\n",
    "        \n",
    "        # Depolarizing quantum errors\n",
    "        error_1 = noise.depolarizing_error(r1, 1)\n",
    "        error_2 = noise.depolarizing_error(r2, 2)\n",
    "        depolnum = 4/(4-1)\n",
    "        \n",
    "        designed_noise_model.add_all_qubit_quantum_error(bit_flip, \"reset\")\n",
    "        designed_noise_model.add_all_qubit_quantum_error(error_1, ['unitary'])\n",
    "        designed_noise_model.add_all_qubit_quantum_error(error_2, ['cz'])\n",
    "        designed_noise_model.add_all_qubit_quantum_error(bit_flip, \"measure\")\n",
    "        #print(designed_noise_model)\n",
    "\n",
    "        \n",
    "        # t_qc_noisy = transpile(qc, sim_noise)\n",
    "        \n",
    "        # measure all qubits\n",
    "        qc.measure_all()\n",
    "        \n",
    "        # get probabilites from ideal circuit\n",
    "        result_ideal = sim_ideal.run(qc).result()\n",
    "        state = result_ideal.get_statevector()\n",
    "        pU = state.probabilities()\n",
    "        \n",
    "        # Create noisy simulator backend and transpile circuit\n",
    "        sim_noise = AerSimulator(noise_model=designed_noise_model)\n",
    "        qct = transpile(qc, sim_noise) # transpile for noisy basis gates\n",
    "        # get noisy probabilites\n",
    "        result_noisy = sim_noise.run(qct, shots=Nshots).result()\n",
    "        probs_noisy = prob_getcounts(result = result_noisy, qc = qc)\n",
    "        \n",
    "        #compute pu(x^exp)\n",
    "        puexp = get_puexp(probdict_noisy = probs_noisy, pU = pU)\n",
    "        \n",
    "        #compute entropy\n",
    "        entropy = compute_entropy(probs = np.array(list(probs_noisy.values())) )\n",
    "        \n",
    "        #compute cross entropy and cross entropy difference\n",
    "        crentropy_diff, crentropy = cross_entropy_est(probdict_noisy = result_noisy.get_counts(qc), pU = pU )\n",
    "        #crentropy_diff0, crentropy0 = cross_entropy_est(probdict_noisy = result_ideal.get_counts(qc), pU = pU) # to check if the same answer is given for r = 0\n",
    "        #print(\"crentropy_diff0-crentropy_diff\", crentropy_diff0-crentropy_diff)\n",
    "        # compute iprk\n",
    "        IPR_k = [compute_IPRK(probdict_noisfree = result_noisy.get_counts(qc), pU = pU, k = k) for k in ks]\n",
    "        \n",
    "        #compute alpha digital eq 19 in paper\n",
    "        alpha_dig = alpha_digital(r = r, depth=depth, num_qubits = num_qubits)\n",
    "        #append to output        \n",
    "        #print([float(IPR_k[ik]) for ik in range(len(ks))])\n",
    "        tempdf = pd.DataFrame([[alpha_dig, tuple(puexp), ninstance, num_qubits, depth, tuple(pU), r, \n",
    "                                entropy, crentropy, crentropy_diff, Nshots] + [IPR_k[ik] for ik in range(len(ks))]], \n",
    "                              columns= ['alpha_dig', 'puexp', 'ninstance', 'num_qubits', 'depth', 'pU', 'r',\n",
    "                                        'entropy','cross_entropy', 'cross_entropy_diff','nshots']+ ['IPR%i'%k for k in ks])\n",
    "        df = pd.concat([df, tempdf])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532d02c-5f0f-4f06-9ce0-7f4674165815",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmaster = pd.DataFrame(columns= ['alpha_dig', 'puexp', 'ninstance', 'num_qubits', 'depth', 'pU','entropy','cross_entropy', 'cross_entropy_diff','nshots']+['IPR%i'%k for k in ks])\n",
    "dfmaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e42d11-f4fd-4943-8a84-acf92929f2e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#depth_range = np.arange(20,41,5)\n",
    "depth_range = list(np.arange(5,20,1)) + [20,25,30,35,40]\n",
    "#rs = np.array([0, 0.0005, 0.001, 0.002, 0.005, 0.01])\n",
    "rs = np.array([0.02  , 0.    , 0.001 , 0.0005, 0.002 , 0.005 , 0.01  ])\n",
    "Ninstances = 10\n",
    "shape = rs.shape + (Ninstances,) + depth_range.shape\n",
    "depth5, cross_entropy5, cross_entropy_diff5, IPRK5, entropy5 = np.zeros(shape), np.zeros(shape), np.zeros(shape), np.zeros(rs.shape + (Ninstances,)+ ks.shape +depth_range.shape), np.zeros(shape)\n",
    "\n",
    "for j in range(len(rs)):\n",
    "    r = rs[j]\n",
    "    print(\"r\", r)\n",
    "    for i in range(Ninstances):\n",
    "        df_qs = entropy_vs_depth(num_qubits = 15, Nshots = int(1e3), r = r, depth_range = depth_range, ks=ks, ninstance = i)\n",
    "        dfmaster = pd.concat([dfmaster, df_qs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd060b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmaster.to_csv('/home/IPP-HGW/joag/homework/db_qcqi_exam_final_5to19_20_40_step5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmaster_stds = pd.DataFrame(columns= ['alpha_dig', 'ninstance', 'num_qubits', 'depth', 'r',\n",
    "                                        'entropy','cross_entropy', 'cross_entropy_diff','nshots']+ ['IPR%i'%k for k in np.arange(2,11,2)])\n",
    "for d in sorted(dfmaster['depth'].unique()):\n",
    "    for r in sorted(dfmaster['r'].unique()):\n",
    "        inds = dfmaster['r'].isin([r]) & dfmaster['depth'].isin([d])\n",
    "        tdfm = dfmaster[inds].std()\n",
    "        tempdf = pd.DataFrame([tdfm], columns= ['alpha_dig', 'ninstance', 'num_qubits', 'depth', 'r',\n",
    "                                            'entropy','cross_entropy', 'cross_entropy_diff','nshots']+ ['IPR%i'%k for k in np.arange(2,11,2)])\n",
    "        dfmaster_stds = pd.concat([dfmaster_stds, tempdf])\n",
    "dfmaster_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmaster_stds.to_csv('/home/IPP-HGW/joag/homework/db_qcqi_exam_std_5to19_20_40_step5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d3f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmaster_mean_noprobs = pd.DataFrame(columns= ['alpha_dig', 'ninstance', 'num_qubits', 'depth', 'r',\n",
    "                                        'entropy','cross_entropy', 'cross_entropy_diff','nshots']+ ['IPR%i'%k for k in np.arange(2,11,2)])\n",
    "for d in sorted(dfmaster['depth'].unique()):\n",
    "    for r in sorted(dfmaster['r'].unique()):\n",
    "        inds = dfmaster['r'].isin([r]) & dfmaster['depth'].isin([d])\n",
    "\n",
    "        tdfm = dfmaster[inds].mean()\n",
    "        tempdf = pd.DataFrame([tdfm], columns= ['alpha_dig', 'puexp', 'ninstance', 'num_qubits', 'depth', 'pU', 'r',\n",
    "                                            'entropy','cross_entropy', 'cross_entropy_diff','nshots']+ ['IPR%i'%k for k in np.arange(2,11,2)])\n",
    "        dfmaster_mean_noprobs = pd.concat([dfmaster_mean_noprobs, tempdf])\n",
    "dfmaster_mean_noprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmaster_mean_noprobs.to_csv('/home/IPP-HGW/joag/homework/db_qcqi_exam_means_noprobs_5to19_20_40_step5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f706404",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"dfmaster_mean = pd.DataFrame(columns= ['alpha_dig', 'puexp', 'ninstance', 'num_qubits', 'depth', 'pU', 'r',\n",
    "                                        'entropy','cross_entropy', 'cross_entropy_diff','nshots']+ ['IPR%i'%k for k in np.arange(2,11,2)])\n",
    "for d in sorted(dfmaster['depth'].unique()):\n",
    "    for r in sorted(dfmaster['r'].unique()):\n",
    "        inds = dfmaster['r'].isin([r]) & dfmaster['depth'].isin([d])\n",
    "        pus = []\n",
    "        puexps = []\n",
    "        for i,row in dfmaster[['pU', 'puexp']].iterrows():\n",
    "            puexps.append(np.array(list(row['puexp'])))\n",
    "            pus.append(np.array(list(row['pU'])))\n",
    "        tdfm = dfmaster[inds].mean()\n",
    "        tdfm['pU'] = np.mean(np.array(pus), axis = 0)\n",
    "        tdfm['puexp'] = np.array(puexps), axis = 0\n",
    "        tempdf = pd.DataFrame([tdfm], columns= ['alpha_dig', 'puexp', 'ninstance', 'num_qubits', 'depth', 'pU', 'r',\n",
    "                                            'entropy','cross_entropy', 'cross_entropy_diff','nshots']+ ['IPR%i'%k for k in np.arange(2,11,2)])\n",
    "        dfmaster_mean = pd.concat([dfmaster_mean, tempdf])\n",
    "dfmaster_mean\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48329802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfmaster_mean.to_csv('/home/IPP-HGW/joag/homework/db_qcqi_exam_mean_5to19_20_40_step5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize as clnormalize\n",
    "num_qubit = max(dfmaster['num_qubits'].unique())\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "viridis = cm.get_cmap('viridis', 20)\n",
    "sm = cm.ScalarMappable(cmap=viridis, norm = clnormalize(dfmaster['r'].unique()[0], dfmaster['r'].unique()[-1]))\n",
    "ind_d = dfmaster_mean_noprobs['depth'].isin([15, 16, 17, 18, 19, 20, 25, 30, 35, 40])\n",
    "for r in dfmaster_mean_noprobs['r'].unique():\n",
    "    indr = dfmaster_mean_noprobs['r'].isin([r])\n",
    "    items = dfmaster_mean_noprobs[['depth', 'cross_entropy_diff', 'alpha_dig']][indr&ind_d]\n",
    "    line1 = ax.plot(items['depth'], items['cross_entropy_diff'], '-X', label = '$r_{est} = %.3f$'%r, c = viridis(r*50))\n",
    "    line2 = ax.plot(items['depth'], items['alpha_dig'], '--o', label = '$r_{dig} = %.3f$'%r, c = viridis(r*50))\n",
    "    ebar1 = ax.errorbar(items['depth']), items['cross_entropy_diff'],\n",
    "                        yerr=items['cross_entropy_diff'],ecolor = viridis(r*50), color = viridis(r*50))\n",
    "plt.colorbar(sm)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Fidelity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pralpha_z(z, alpha):\n",
    "    \"\"\"\n",
    "    z = log(Np)\n",
    "    \"\"\"\n",
    "    return np.exp(z - np.exp(z))*(1 + alpha*(np.exp(z) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.linspace(-10,5,100)\n",
    "alphas = np.array([1, 0.43, 0.18, 0])\n",
    "for alpha in alphas:\n",
    "    praz = pralpha_z(z = z, alpha = alpha)\n",
    "    plt.plot(z, praz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for analytical expression of Porter Thomas distr\n",
    "z = np.linspace(-8,4,1000)\n",
    "colors = ['c', 'y', 'b', 'r', 'C1', 'C2']\n",
    "depth = max(dfmaster['depth'].unique())\n",
    "num_qubits = max(dfmaster['num_qubits'].unique())\n",
    "print(num_qubits)\n",
    "i = 0\n",
    "plt.figure(figsize=(10,10))\n",
    "rs = dfmaster['r'].unique()\n",
    "rs.sort()\n",
    "\n",
    "for r in rs:\n",
    "    if r == 0.01:\n",
    "        continue\n",
    "    indr = dfmaster['r'].isin([r]) & dfmaster['depth'].isin([depth]) & dfmaster['num_qubits'].isin([num_qubits] )\n",
    "    items = dfmaster[['puexp', 'cross_entropy_diff', 'pU', 'alpha_dig']][indr]\n",
    "    meanpu = np.mean(np.array([np.array(list(tup)) for tup in items['pU']]), axis=0)\n",
    "    # setting the last puexp as the measurement distribution because the number of samples drawn \n",
    "    #is not equal for each circuit drawn from the ensemble for which the sampling is done \n",
    "    lastpuexp = np.array(items['puexp'][[(i == 4) for i in range(5)]][0])\n",
    "    \n",
    "    #computing Np\n",
    "    Np = 2**(num_qubits)*lastpuexp\n",
    "    \n",
    "    # computing log Np with redefinition for better numerics\n",
    "    logNp = num_qubits*np.log(2) + np.log(lastpuexp)\n",
    "    praz = pralpha_z(z = z, alpha = items['alpha_dig'].mean(axis=0))\n",
    "    #print(items['cross_entropy_diff'])\n",
    "    alpha_est = items['cross_entropy_diff'].mean(axis=0)\n",
    "    alpha_dig = items['alpha_dig'].mean(axis=0)\n",
    "    plt.hist(logNp, label='$\\\\alpha_{est} = %.2f$'%alpha_est, color = viridis(alpha_est), bins = 20, density = True, alpha=0.5 - 0.05*i)\n",
    "    plt.plot(z, praz, '-', label = '$\\\\alpha_{dig} = %.2f}$'%alpha_dig, color = viridis(alpha_dig))#, np.exp(-logNp_ideal)\n",
    "    i+=1\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f9292-5cfd-4499-8a26-60610dcc0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_yaxis_iprk(dfmaster, k, num_qubits, depth, r):\n",
    "    iprkdf = dfmaster[['r','depth']+['IPR%i'%i for i in np.arange(2,11,2)]]\n",
    "    indiprk = iprkdf['r'].isin([r]) & iprkdf['depth'].isin([depth])\n",
    "    #print(iprkdf[indiprk])\n",
    "    #print(iprkdf[indiprk]['IPR%i'%k])\n",
    "    iprk = iprkdf[indiprk]['IPR%i'%k].mean()\n",
    "    # for such a large number it is more convenient to use the logarithm\n",
    "    lognumber = (k-1)*np.log(2**(num_qubits)*iprk) - sum([np.log(i) for i in range(2,k+1)])\n",
    "    return np.exp(lognumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_yaxis_iprk(dfmaster = dfmaster, k = 2, num_qubits = max(dfmaster['num_qubits'].unique()), depth = 5, r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76550fca-cb28-4ba6-bd79-a76641bcf4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iprkplot(depth, df, ks = np.arange(2,11,2), r= 0.01):\n",
    "    plt.figure()\n",
    "    num_qubits = max(df['num_qubits'].unique())\n",
    "    for k in ks:\n",
    "        iprk = []\n",
    "        ds = []\n",
    "        for d in depth:\n",
    "            iprk_i = compute_yaxis_iprk(dfmaster = df, k = k, num_qubits = num_qubits, depth = d, r = r)\n",
    "            iprk.append(iprk_i)\n",
    "            ds.append(d)\n",
    "        plt.plot(ds, iprk, '-o', label = '$k = %i$'%(k)) \n",
    "        #plt.ylim(0.99,5)\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel(\"Depth\")\n",
    "        plt.ylabel(\"$IPRK^{(k)} N^{k-1}/k!$\")\n",
    "        \n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5621ef-7299-41ce-9a2e-bfc05f132304",
   "metadata": {},
   "outputs": [],
   "source": [
    "iprkplot(depth = np.arange(5, 20, 1), df = dfmaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aafcdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paperplots(depth, ce, ced, e, r, df_std):\n",
    "    title = \"Mean value for $r = %.3f$\"%r\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.plot(depth, ce, '-ok')\n",
    "    plt.errorbar(depth, ce, yerr = df_std['cross_entropy'])\n",
    "    plt.xlabel(\"Depth\")\n",
    "    plt.ylabel(\"Mean cross-entropy\")\n",
    "    plt.savefig('/home/IPP-HGW/joag/homework/figures_qcqi_exam/cross_entropy_r_%.3f'%r + '.png')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.plot(depth, ced, '-ok')\n",
    "    plt.errorbar(depth, ced, yerr = df_std['cross_entropy_diff'])\n",
    "    plt.xlabel(\"Depth\")\n",
    "    plt.ylabel(\"Fidelity\")\n",
    "    plt.savefig('/home/IPP-HGW/joag/homework/figures_qcqi_exam/cross_entropy_diff_r_%.3f'%r + '.png')\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.plot(depth, e, '-ok')\n",
    "    plt.plot(depth, np.ones(depth.shape)*(15*np.log(2)-1 + 0.577), '--r', label='$H(p_U))$')\n",
    "    plt.errorbar(depth, e, yerr = df_std['entropy'])\n",
    "    plt.xlabel(\"Depth\")\n",
    "    plt.ylabel(\"Mean entropy\")\n",
    "    plt.savefig('/home/IPP-HGW/joag/homework/figures_qcqi_exam/entropy_r_%.3f'%r + '.png')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f21aea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in sorted(dfmaster_mean_noprobs['r'].unique()):\n",
    "    indr = dfmaster_mean_noprobs['r'].isin([r])\n",
    "    cetest = dfmaster_mean_noprobs['cross_entropy'][indr]\n",
    "    cedtest = dfmaster_mean_noprobs['cross_entropy_diff'][indr]\n",
    "    etest = dfmaster_mean_noprobs['entropy'][indr]\n",
    "    paperplots(depth = np.arange(5, 20, 1), ce = cetest, ced = cedtest, e = etest, r = r, df_std = dfmaster_stds[indr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5bb57d-1aaa-4b1e-bcde-0565e684764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_error(atqubit,atdepth, ondepth, onqubit):\n",
    "    return (atqubit == onqubit) & (atdepth == ondepth)\n",
    "\n",
    "def gen_rqc_single_error(num_qubits, depth, errortype = 'x', add_error = add_error, atqubit = False, atdepth = False, operands = std_operands, seed = 2022):\n",
    "    reg = [i for i in range(num_qubits)]\n",
    "    random.seed(seed)\n",
    "    qc = QuantumCircuit(num_qubits, num_qubits)\n",
    "    qc.h([i for i in range(qc.num_qubits)])\n",
    "    choices = [None]*num_qubits\n",
    "    for i in range(depth):\n",
    "        # single-qubit gate layer\n",
    "        for j in range(num_qubits):\n",
    "            # print(i,j,add_error(atqubit = atqubit,atdepth = atdepth, ondepth = i, onqubit =j))\n",
    "            choice = random_gate(num_qubits=1, operands = operands)\n",
    "            while choice == choices[j]:\n",
    "                choice = random_gate(num_qubits=1, operands = operands)\n",
    "            choices[j] = choice # store to make sure the same gate does not get chosen two times consequtively\n",
    "            qc.unitary(choice, [j], label = choice.label)\n",
    "            if add_error(atqubit = atqubit,atdepth = atdepth, ondepth = i, onqubit =j):\n",
    "                if errortype == 'x':\n",
    "                    qc.x(atqubit)\n",
    "                if errortype == 'z':\n",
    "                    qc.z(atqubit)\n",
    "                \n",
    "        # 2-qubit gate layer\n",
    "        if i%2 == 0:\n",
    "            igate = np.arange(0,num_qubits-2, 2)\n",
    "            for j in igate: \n",
    "                qc.cz(j, j+1)\n",
    "        else:\n",
    "            igate = np.arange(1,num_qubits-1, 2)\n",
    "            for j in igate:\n",
    "                qc.cz(j, j+1)\n",
    "        qc.barrier()\n",
    "                   \n",
    "    return qc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd73b8-51fa-46ec-91b1-0d0d689390ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrc3 = gen_rqc_single_error(num_qubits=3, depth = 3, atdepth=2, atqubit=2, errortype='z')\n",
    "qrc3.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70c487-426f-4eac-9d30-a6f80e3d8566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "def fig3(num_qubits, depth, Nshots = 1, errortype = 'x'):\n",
    "    \n",
    "    qc_ideal = gen_rqc(num_qubits=num_qubits, depth = depth)\n",
    "    qc_ideal.save_statevector()\n",
    "    \n",
    "    # get probabilites from ideal circuit\n",
    "    \n",
    "    # Create ideal simulator backend and transpile circuit\n",
    "    sim_ideal = AerSimulator()\n",
    "    t_qc = transpile(qc_ideal, sim_ideal)\n",
    "    result_ideal = sim_ideal.run(t_qc, shots=Nshots).result()\n",
    "    state_ideal = result_ideal.get_statevector()\n",
    "    pideal = state_ideal.probabilities()\n",
    "\n",
    "    perror = np.zeros((num_qubits, depth, 2**num_qubits))\n",
    "    for atqubit in np.arange(0,num_qubits,1):\n",
    "        for atdepth in np.arange(0,depth, 1):\n",
    "            # print(atqubit, atdepth)\n",
    "            qc = gen_rqc_single_error(num_qubits=num_qubits, depth = depth, errortype = errortype, atdepth=atdepth, atqubit=atqubit)\n",
    "            qc.save_statevector()\n",
    "            \n",
    "            \n",
    "            t_qc_paulierror = transpile(qc, sim_ideal)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # get probabilites from circuit with the one pauli error\n",
    "            result_paulierror = sim_ideal.run(t_qc_paulierror, shots=Nshots).result()\n",
    "            state_error = result_paulierror.get_statevector()\n",
    "            perror[atqubit,atdepth] += state_error.probabilities()\n",
    "        \n",
    "    # sorting\n",
    "    # print(pideal.shape)\n",
    "    # print(np.mean(perror, axis=0).shape)\n",
    "    # print(np.mean(np.mean(perror, axis=0), axis=0))\n",
    "    psorted = [pipe for pipe in zip(*sorted(zip(list(pideal), list(np.mean(np.mean(perror, axis=0), axis=0)))))]\n",
    "    \n",
    "    return psorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d805103-3a46-41da-93db-376354cbd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "psortx = fig3(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Used X-gate for Pauli error\")\n",
    "plt.plot(np.arange(0,len(psortx[0]), 1), list(psortx[0]), label='No errors')\n",
    "plt.plot(np.arange(0,len(psortx[0]), 1), list(psortx[1]), label='One Pauli error(averaged)')\n",
    "plt.xlabel('Bit-string index $j (p(x_j)$-ordered)')\n",
    "plt.ylabel('$Np$')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7095bbc-81bc-42e9-b87d-ee7aec359d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psortz = fig3(10,10, errortype='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c2f90-ddbf-4dba-8345-6e823e272164",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Used Z-gate for Pauli error\")\n",
    "plt.plot(np.arange(0,len(psortz[0]), 1), list(psortz[0]), label='No errors')\n",
    "plt.plot(np.arange(0,len(psortz[0]), 1), list(psortz[1]), label='One Pauli error(averaged)')\n",
    "plt.xlabel('Bit-string index $j (p(x_j)$-ordered)')\n",
    "plt.ylabel('$Np$')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b244080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05de8dd5913c4428a1f310c96eb3f024": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "09f0e0afdeaa40daae903d7521fdf7db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2b624c285b44436e88b4c286ffea31ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_05de8dd5913c4428a1f310c96eb3f024",
       "style": "IPY_MODEL_35e740a53f7747e79e7999a620c5e9cc",
       "value": "<h5>Message</h5>"
      }
     },
     "30df61fb1fb04917a9d907412714dd16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "margin": "0px 0px 10px 0px"
      }
     },
     "3585c23f0e5449bdbadd61756bcd4675": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "margin": "0px 0px 0px 37px",
       "width": "600px"
      }
     },
     "35e740a53f7747e79e7999a620c5e9cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4b5f09a278a147da8ea8647bb9e2c6f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5da6463630a54281874895a0f16c0f1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "61cb7652beba4c7eabdb62898ef4a8b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f914c521d4c24ed28aa78947335c0911",
        "IPY_MODEL_f6ae20b52154490a992e8f35bc628571",
        "IPY_MODEL_eabe33d923404865b39a729b74ccf4ff",
        "IPY_MODEL_be2b2e9735f84646922e866be8a45ea6",
        "IPY_MODEL_2b624c285b44436e88b4c286ffea31ce"
       ],
       "layout": "IPY_MODEL_3585c23f0e5449bdbadd61756bcd4675"
      }
     },
     "679a5f9559c5480ba478ac8021289278": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "button_style": "primary",
       "description": "Clear",
       "layout": "IPY_MODEL_6853b462f2ed488dbc176038ed648da4",
       "style": "IPY_MODEL_877a5b5067c94b86a3417e8ef5085e49"
      }
     },
     "6853b462f2ed488dbc176038ed648da4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "grid_area": "right",
       "padding": "0px 0px 0px 0px",
       "width": "70px"
      }
     },
     "69442968b7104338a2403dba484bd9ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "GridBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_679a5f9559c5480ba478ac8021289278"
       ],
       "layout": "IPY_MODEL_dbb70116367c40b79ed051059138785f"
      }
     },
     "7ceac2bc5afa4dc2b4c57e164f3fbdaf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "145px"
      }
     },
     "877a5b5067c94b86a3417e8ef5085e49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "937adb1980624ecb8a3da9cc84ef3cfc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "190px"
      }
     },
     "a8e9d2b067d2479fadc59ea3dd86cecd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_30df61fb1fb04917a9d907412714dd16",
       "style": "IPY_MODEL_5da6463630a54281874895a0f16c0f1f",
       "value": "<p style='font-family: IBM Plex Sans, Arial, Helvetica, sans-serif; font-size: 20px; font-weight: medium;'>Circuit Properties</p>"
      }
     },
     "b2cb7f70edec4f92a4624571b69a11f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "be2b2e9735f84646922e866be8a45ea6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f1bd36fb4a084689b99871bb81d83faa",
       "style": "IPY_MODEL_09f0e0afdeaa40daae903d7521fdf7db",
       "value": "<h5>Queue</h5>"
      }
     },
     "c6a4cd45a1dc48c6b018cf93be2e93ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "dbb70116367c40b79ed051059138785f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "grid_template_areas": "\n                                       \". . . . right \"\n                                        ",
       "grid_template_columns": "20% 20% 20% 20% 20%",
       "width": "100%"
      }
     },
     "eabe33d923404865b39a729b74ccf4ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fcb16610d2764532818cbbbb7d79ce6b",
       "style": "IPY_MODEL_c6a4cd45a1dc48c6b018cf93be2e93ce",
       "value": "<h5>Status</h5>"
      }
     },
     "f1bd36fb4a084689b99871bb81d83faa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "70px"
      }
     },
     "f6ae20b52154490a992e8f35bc628571": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7ceac2bc5afa4dc2b4c57e164f3fbdaf",
       "style": "IPY_MODEL_b2cb7f70edec4f92a4624571b69a11f7",
       "value": "<h5>Backend</h5>"
      }
     },
     "f914c521d4c24ed28aa78947335c0911": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_937adb1980624ecb8a3da9cc84ef3cfc",
       "style": "IPY_MODEL_4b5f09a278a147da8ea8647bb9e2c6f8",
       "value": "<h5>Job ID</h5>"
      }
     },
     "fcb16610d2764532818cbbbb7d79ce6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "95px"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
